#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆå°è¯´æ”¹å†™ç³»ç»Ÿ - æ ¸å¿ƒåŠŸèƒ½ç‰ˆæœ¬
ä¸“æ³¨äºï¼šå°è¯´å¯¼å…¥ã€æ–‡æœ¬åˆ†å‰²ã€æ™ºèƒ½æ”¹å†™ã€æ ‡å‡†æ ¼å¼è¾“å‡º
"""

import json
import re
import logging
import time
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime
from openai import OpenAI
from openai.types.chat import ChatCompletion

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from document_importer_simple import SimpleDocumentImporter
from text_splitter_simple import SimpleTextSplitter
from prompt_manager_simple import SimplePromptManager
from output_formatter_simple import SimpleOutputFormatter


class SimpleNovelRewriter:
    """ç®€åŒ–ç‰ˆå°è¯´æ”¹å†™å™¨"""
    
    def __init__(self, config_path: str = "config_simple.json"):
        # åŠ è½½é…ç½®
        self.config = self._load_config(config_path)
        
        # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=self.config["api_key"],
            base_url=self.config.get("api_url", "https://api.deepseek.com")
        )
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.document_importer = SimpleDocumentImporter()
        self.text_splitter = SimpleTextSplitter(
            max_chunk_size=self.config.get("chunk_size", 2000),
            min_chunk_size=self.config.get("min_chunk_size", 300)
        )
        self.prompt_manager = SimplePromptManager(self.config)
        self.output_formatter = SimpleOutputFormatter()
        
        # å­˜å‚¨å¤„ç†ç»“æœ
        self.processed_chunks = []
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
    
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        default_config = {
            "api_key": "your_api_key_here",
            "api_url": "https://api.deepseek.com",
            "model": "deepseek-chat",
            "temperature": 0.8,
            "max_tokens": 2000,
            "chunk_size": 2000,
            "min_chunk_size": 300,
            "max_retries": 2,
            "retry_delay": 1,
            "worldview": "ç°ä»£éƒ½å¸‚ä¸–ç•Œè§‚",
            "writing_style": "ç®€æ´æ˜äº†çš„å™äº‹é£æ ¼",
            "literary_techniques": [
                "ä¿æŒè¯­è¨€æµç•…è‡ªç„¶",
                "é€‚å½“è¿ç”¨ç¯å¢ƒæå†™",
                "ç¡®ä¿å¯¹è¯çœŸå®å¯ä¿¡"
            ]
        }
        
        try:
            if not Path(config_path).exists():
                with open(config_path, 'w', encoding='utf-8') as f:
                    json.dump(default_config, f, indent=2, ensure_ascii=False)
                print(f"å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶ {config_path}ï¼Œè¯·å¡«å…¥æ‚¨çš„APIå¯†é’¥")
                exit(0)
            
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
                return {**default_config, **user_config}
        except Exception as e:
            print(f"é…ç½®åŠ è½½å¤±è´¥: {str(e)}")
            exit(1)
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('novel_rewriter_simple.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def process_file(self, input_path: Path) -> Optional[Path]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {input_path}")
            
            # æ¸…ç©ºä¹‹å‰çš„ç»“æœ
            self.processed_chunks = []
            
            # 1. å¯¼å…¥æ–‡æ¡£
            print("ğŸ“– æ­£åœ¨å¯¼å…¥æ–‡æ¡£...")
            document_data = self.document_importer.import_document(input_path)
            text = document_data['full_text']
            
            print(f"âœ“ æ–‡æ¡£å¯¼å…¥æˆåŠŸ: {document_data['title']}")
            print(f"   å­—æ•°: {document_data['word_count']}")
            
            # 2. åˆ†å‰²æ–‡æœ¬
            print("âœ‚ï¸ æ­£åœ¨åˆ†å‰²æ–‡æœ¬...")
            text_chunks = self.text_splitter.split_text(text)
            print(f"âœ“ æ–‡æœ¬åˆ†å‰²å®Œæˆï¼Œå…± {len(text_chunks)} ä¸ªæ–‡æœ¬å—")
            
            # 3. å¤„ç†æ¯ä¸ªæ–‡æœ¬å—
            output_dir = Path("output")
            output_dir.mkdir(exist_ok=True)
            
            structured_output_path = output_dir / f"structured_{input_path.stem}.json"
            final_text_path = output_dir / f"rewritten_{input_path.stem}.txt"
            
            print("ğŸ”„ æ­£åœ¨æ”¹å†™æ–‡æœ¬å—...")
            
            for i, chunk in enumerate(text_chunks):
                chunk_id = f"chunk_{i+1}"
                
                # æ„å»ºæç¤ºè¯
                prompt_messages = self.prompt_manager.build_prompt(
                    text=chunk,
                    chunk_id=chunk_id,
                    metadata={
                        "source_file": input_path.name,
                        "document_title": document_data['title']
                    }
                )
                
                # è°ƒç”¨APIæ”¹å†™
                rewritten_text = self._rewrite_with_api(prompt_messages, chunk.text)
                
                # æ ¼å¼åŒ–è¾“å‡º
                structured_output = self.output_formatter.format_output(
                    original_text=chunk.text,
                    rewritten_text=rewritten_text,
                    chunk_id=chunk_id,
                    metadata={
                        "word_count": len(chunk.text),
                        "timestamp": datetime.now().isoformat()
                    }
                )
                
                self.processed_chunks.append(structured_output)
                
                # æ˜¾ç¤ºè¿›åº¦
                rewritten_text_str = rewritten_text if isinstance(rewritten_text, str) else str(rewritten_text)
                print(f"   è¿›åº¦: {i+1}/{len(text_chunks)} - å­—æ•°: {len(rewritten_text)}")
                time.sleep(0.5)  # é¿å…APIè°ƒç”¨è¿‡äºé¢‘ç¹
            
            # 4. ä¿å­˜ç»“æœ
            print("ğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœ...")
            
            # ä¿å­˜ç»“æ„åŒ–æ•°æ®
            with open(structured_output_path, 'w', encoding='utf-8') as f:
                json.dump({
                    "metadata": {
                        "title": document_data['title'],
                        "author": document_data['author'],
                        "processing_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "total_chunks": len(self.processed_chunks),
                        "original_word_count": document_data['word_count']
                    },
                    "chunks": self.processed_chunks
                }, f, ensure_ascii=False, indent=2)
            
            # ç”Ÿæˆæœ€ç»ˆæ–‡æœ¬
            final_text = self.output_formatter.assemble_final_text(self.processed_chunks)
            with open(final_text_path, 'w', encoding='utf-8') as f:
                f.write(final_text)
            
            print(f"âœ“ å¤„ç†å®Œæˆ!")
            print(f"   ç»“æ„åŒ–æ•°æ®: {structured_output_path}")
            print(f"   æœ€ç»ˆæ–‡æœ¬: {final_text_path}")
            
            return structured_output_path
            
        except Exception as e:
            self.logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def _rewrite_with_api(self, messages: List[Dict], original_text: str) -> str:
        """è°ƒç”¨APIè¿›è¡Œæ–‡æœ¬æ”¹å†™"""
        for attempt in range(self.config["max_retries"]):
            try:
                response: ChatCompletion = self.client.chat.completions.create(
                    model=self.config["model"],
                    messages=messages,
                    temperature=self.config["temperature"],
                    max_tokens=self.config["max_tokens"],
                    top_p=0.9,
                    frequency_penalty=0.2
                )
                
                result = response.choices[0].message.content.strip()
                
                # æ£€æŸ¥å­—æ•°æ˜¯å¦è¿‡çŸ­
                if len(result) < len(original_text) * 0.6:
                    if attempt < self.config["max_retries"] - 1:
                        time.sleep(self.config["retry_delay"] * (attempt + 1))
                        continue
                    else:
                        # æœ€åä¸€æ¬¡å°è¯•ï¼Œè¿”å›åŸæ–‡
                        return original_text
                
                return result
                
            except Exception as e:
                if attempt == self.config["max_retries"] - 1:
                    self.logger.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
                    return original_text  # è¿”å›åŸæ–‡ä½œä¸ºå›é€€
                time.sleep(self.config["retry_delay"] * (attempt + 1))
        
        return original_text
    
    def batch_process(self, directory: str = "source") -> List[Path]:
        """æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„æ–‡ä»¶"""
        source_dir = Path(directory)
        if not source_dir.exists():
            print(f"é”™è¯¯ï¼šç›®å½•ä¸å­˜åœ¨: {directory}")
            return []
        
        # æŸ¥æ‰¾æ‰€æœ‰TXTæ–‡ä»¶
        txt_files = list(source_dir.glob("*.txt"))
        
        if not txt_files:
            print(f"åœ¨ {directory} ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°TXTæ–‡ä»¶")
            return []
        
        print(f"æ‰¾åˆ° {len(txt_files)} ä¸ªTXTæ–‡ä»¶:")
        for i, file in enumerate(txt_files, 1):
            print(f"  {i}. {file.name}")
        
        results = []
        for file_path in txt_files:
            print(f"\nâ–¶ å¤„ç†æ–‡ä»¶: {file_path.name}")
            result = self.process_file(file_path)
            if result:
                results.append(result)
        
        return results


def main():
    """ä¸»å‡½æ•°"""
    print("""
    =========================================
     ç®€åŒ–ç‰ˆå°è¯´æ”¹å†™ç³»ç»Ÿ v1.0
     æ ¸å¿ƒåŠŸèƒ½ï¼šå¯¼å…¥ã€åˆ†å‰²ã€æ”¹å†™ã€è¾“å‡º
    =========================================
    """)
    
    # åˆå§‹åŒ–æ”¹å†™å™¨
    rewriter = SimpleNovelRewriter()
    
    # æ£€æŸ¥sourceç›®å½•
    source_dir = Path("source")
    if not source_dir.exists():
        source_dir.mkdir(exist_ok=True)
        print(f"å·²åˆ›å»ºsourceç›®å½•ï¼Œè¯·æ”¾å…¥è¦å¤„ç†çš„TXTæ–‡ä»¶")
        return
    
    # æŸ¥æ‰¾è¦å¤„ç†çš„æ–‡ä»¶
    txt_files = list(source_dir.glob("*.txt"))
    
    if not txt_files:
        print("sourceç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°TXTæ–‡ä»¶")
        print("å·²åˆ›å»ºç¤ºä¾‹æ–‡ä»¶ï¼šexample.txt")
        example_path = source_dir / "example.txt"
        example_content = """è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹å°è¯´å†…å®¹ã€‚

ç¬¬ä¸€ç«  å¼€å§‹

é•‡ä¸Šçš„é‡‘åº“ç»™å››ä¸ªåŠ«åŒªæŠ¢äº†ï¼Œæ•å¤´æŸ³æš—å•æªåŒ¹é©¬è¿å¤œèµ¶åœ¨ä»–ä»¬å‰å¤´ï¼Œåœ¨å››ä¸ªåŠ«åŒªçš„å¿…ç»ä¹‹è·¯â€•â€•åä¸‰å±±å±±è„šçš„è·¯ä¸Šç­‰å¾…ã€‚

ã€Œè€å¤§ï¼Œæˆ‘ä»¬è¿™æ¬¡çœŸæ˜¯å¹²äº†ä¸€ç¥¨å¤§çš„ï¼ã€ä¸€ä¸ªåŠ«åŒªå…´å¥‹åœ°è¯´é“ã€‚

ã€Œå—¯ï¼Œç¡®å®ä¸å°‘ã€‚ã€å¦ä¸€ä¸ªåŠ«åŒªå†·é™åœ°å›ç­”ï¼Œã€Œä½†æˆ‘ä»¬è¿˜æ˜¯è¦å°å¿ƒç‚¹ï¼Œåˆ«è¢«å®˜åºœçš„äººè¿½ä¸Šã€‚ã€

æŸ³æš—å¿ƒä¸­æš—æƒ³ï¼šã€Œè¿™ä¼™åŠ«åŒªçœ‹èµ·æ¥å¾ˆè°¨æ…ï¼Œæˆ‘å¾—æƒ³ä¸ªå¥½åŠæ³•å¯¹ä»˜ä»–ä»¬ã€‚ã€ä»–æ‚„æ‚„åœ°æ‹”å‡ºäº†è…°é—´çš„åˆ€ï¼Œå‡†å¤‡éšæ—¶å‡ºå‡»ã€‚

å¤©è‰²æ¸æš—ï¼Œå±±é—´çš„é£å£°è¶Šæ¥è¶Šå¤§ã€‚æŸ³æš—ç´§æ¡ç€åˆ€æŸ„ï¼Œçœ¼ç¥åšå®šåœ°æ³¨è§†ç€å‰æ–¹çš„é“è·¯ã€‚
"""
        example_path.write_text(example_content, encoding='utf-8')
        txt_files = [example_path]
    
    # å¤„ç†æ–‡ä»¶
    results = rewriter.batch_process()
    
    # æ˜¾ç¤ºç»“æœ
    if results:
        print(f"\nğŸ‰ å¤„ç†å®Œæˆ! å…±å¤„ç† {len(results)} ä¸ªæ–‡ä»¶")
        for result in results:
            print(f"  ç»“æœ: {result.name}")
    else:
        print("\nâŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶")


if __name__ == "__main__":
    main()